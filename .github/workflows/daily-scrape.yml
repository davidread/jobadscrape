name: Daily Scrape

on:
  schedule:
    - cron: '0 1 * * *'  # Runs at 01:00 UTC every day
  workflow_dispatch:      # Allows manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'
    
    - name: Install system dependencies for WeasyPrint
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          libcairo2-dev \
          libpango1.0-dev \
          libgdk-pixbuf2.0-dev \
          libffi-dev \
          shared-mime-info
          
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Install Chromium for Playwright
      run: |    
        # --with-deps installs OS-level browser dependencies too
        # grep filters out progress bar lines that clutter CI logs
        playwright install --with-deps chromium 2>&1 | grep -v '^|'
    
    - name: Run scraper
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        GOOGLE_SERVICE_ACCOUNT_KEY: ${{ secrets.GOOGLE_SERVICE_ACCOUNT_KEY }}
      run: python scrape.py
